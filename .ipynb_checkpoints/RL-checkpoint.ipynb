{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2958668a-f437-4d29-9a17-518f5820aefb",
   "metadata": {},
   "source": [
    "Final report\n",
    "- Describe RL\n",
    "- Describe LOB\n",
    "- What metric are we trying to optimise\n",
    "- Inputs\n",
    "- Literature review\n",
    "- Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68543e12-9c91-4d1f-8aab-2e1e596e8d83",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Todo\n",
    "\n",
    "Saturday:\n",
    "- Check the bid-ask index\n",
    "- Code correctness check\n",
    "  - Verify that neither actor nor critic need each others gradients\n",
    "  - Check the update of log_prob is correct and appropriate (That it is done on the network after retrieveing saved data, after actions and transitions have been taken)\n",
    "  - Perhaps I need to shrink my replay memory size\n",
    "  - Figure out why policy_loss is sometimes negative, it should never be negative\n",
    "  - Clean up excessive cloning\n",
    "  - Minimize data transfers (.cpu().numpy().tolist())\n",
    "  - FIX MY REWARD FUNCTION\n",
    "  - Check buy-sell-buy-sell-buy-sell for reward function\n",
    "- Standardization\n",
    "- We could delineate trading by passing in random durations as episodes rather than the whole dataset (Check that this is a valid approach)\n",
    "- Include timestamps for the Rewards that we save\n",
    "- Do some feature selection\n",
    "- Penalty term for neutral positions\n",
    "- Pretrain actor network\n",
    "  - Freeze the actor network and train the critic network\n",
    "  - Commence full QAC training\n",
    "  \n",
    "Sunday:\n",
    "- Need to figure out MLflow logging\n",
    "- Tensorboard: https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "\n",
    "Monday:\n",
    "- PPO\n",
    "- Long-only policy\n",
    "- Recreating the table on Slide 41 of 56 from this set of lecture slides would be good for our purposes https://www.davidsilver.uk/wp-content/uploads/2020/03/FA.pdf\n",
    "- Soft Actor Critic: https://arxiv.org/abs/1910.07207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03432b8f-6499-49d9-aece-158eaf854b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "from LOB_analysis import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc00e2d-e74d-4860-b7e5-48effc6b700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943d5421-cd65-460d-bc19-2a9630e731d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKET_OPEN = '9:30'\n",
    "MARKET_CLOSE = '16:00'\n",
    "\n",
    "message = pd.read_pickle(r\"../data/AMD_jan_msg.pickle\")\n",
    "orderbook = pd.read_pickle(r\"../data/AMD_jan_odb.pickle\")\n",
    "\n",
    "market_open_idx = message.set_index('time').index.indexer_between_time(MARKET_OPEN, MARKET_CLOSE)\n",
    "\n",
    "message = message.iloc[market_open_idx, :].reset_index(drop=True)\n",
    "orderbook = orderbook.iloc[market_open_idx, :].reset_index(drop=True)\n",
    "data = generate_data(message, orderbook, granularity='5 min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073c0da-5090-4ca9-9d6b-a42010cd616a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Create features\n",
    "\n",
    "**I do not know if standardization is actually a good thing. [CHECK - Ask prof too]**  \n",
    "Standardization will be done using a small window of previous events. This is because the statistical properties change as time moves on, so we standardize w.r.t small prior windows. Standardization benefits ML training since values will stradle 0 and not be too far from it.  \n",
    "\n",
    "**Check if we should reindex time-series data with forward padding and explicitly 0-labels given to these regions.**\n",
    "\n",
    "**BE CAREFUL OF THE CURSE OF DIMENSIONALITY**\n",
    "To understand if the curse of dimensionality is affecting performance, rerun the exact same experiments with fewer features and see if profitability increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac1fb670-8efb-4ebc-9e10-4dd62ad0184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For optimizing the threshold value to produce balanced class labels.\n",
    "\n",
    "Use with scipy.optimize.minimize_scalar\n",
    "\"\"\"\n",
    "def label_eval(threshold, time_horizon = 50):\n",
    "    labels = get_label(data.mid_price, time_horizon = time_horizon, threshold = threshold)\n",
    "    counts = labels.value_counts()\n",
    "    return -(counts / counts.sum()).min()\n",
    "\n",
    "threshold = minimize_scalar(label_eval, bounds=(0, 2)).x\n",
    "labels = get_label(data.mid_price, time_horizon=50, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13d1142-dddf-4411-91a2-85f5c2bc9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize BEFORE time series sampling\n",
    "SAMPLE_SIZE = 20\n",
    "NUM_DATA_COLS = data.shape[1]\n",
    "bid_col_idx = data.columns.get_loc('bid')\n",
    "ask_col_idx = data.columns.get_loc('ask')\n",
    "\n",
    "curr_bid_idx = bid_col_idx + (NUM_DATA_COLS + 1) * (SAMPLE_SIZE - 1)\n",
    "curr_ask_idx = ask_col_idx + (NUM_DATA_COLS + 1) * (SAMPLE_SIZE - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913cd36b-cb1d-4365-9e4c-1853470f3d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 20, 58)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = generate_time_series_samples(data, labels, SAMPLE_SIZE) # This fn performs dropna\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25fb250f-df69-461d-8e39-86b263511c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 1160)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_flatten = X.reshape(X.shape[0], -1)\n",
    "X_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8695be0-f655-4aae-b1e8-4f911785ff10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1250, 1161])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_torch = torch.ones((X_flatten.shape[0], X_flatten.shape[1] + 1))\n",
    "X_torch[:, :-1] = torch.tensor(X_flatten)\n",
    "X_torch = X_torch.to(device)\n",
    "X_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77f51c1-952c-4d9d-9939-f545357a9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids = data.loc[y.index, 'bid'].copy()\n",
    "asks = data.loc[y.index, 'ask'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b685f1-a669-4499-90d4-de1e418e9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(NUM_DATA_COLS * SAMPLE_SIZE + 1, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def get_value(self, state):\n",
    "        return self.value(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee07680-a941-449f-80ef-c9cdea817d7c",
   "metadata": {},
   "source": [
    "Note that actions are:\n",
    "- 0: Short   (Have -1 asset)\n",
    "- 1: Neutral (Have 0 asset)\n",
    "- 2: Long    (Have 1 asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c547c51c-d9d4-41ed-990b-f39bdc0ee5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action = nn.Sequential(\n",
    "            nn.Linear(NUM_DATA_COLS * SAMPLE_SIZE + 1, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_next_portfolio(self, state):\n",
    "        with torch.no_grad():\n",
    "            logits = self.action(state)\n",
    "            probs = Categorical(logits=logits)\n",
    "            action = probs.sample()\n",
    "        return action\n",
    "    \n",
    "    def get_log_prob(self, prev_state, curr_state):\n",
    "        logits = self.action(prev_state)\n",
    "        dist = Categorical(logits=logits)\n",
    "        action = curr_state[..., -1]\n",
    "        return dist.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6a0cef-00e7-49f1-95bc-6afd27edbf3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_reward(prev_state, curr_state, ask_idx, bid_idx, prev_action_idx=-1, trading_fee=1e-4, neutral_penalty=1e-6):\n",
    "    assert (prev_state.dim() == 1) and (curr_state.dim() == 1), \"State provided is not 1 dimensional\"\n",
    "    \n",
    "    valid_actions = [0, 1, 2]\n",
    "    assert (prev_state[prev_action_idx] in valid_actions) and (curr_state[prev_action_idx] in valid_actions), \"Action provided is not in [0, 1, 2] range\"\n",
    "    \n",
    "    prev_is_neutral = prev_state[prev_action_idx] == 1\n",
    "    curr_is_neutral = curr_state[prev_action_idx] == 1\n",
    "    \n",
    "    if prev_is_neutral:\n",
    "        if prev_is_neutral:\n",
    "            # Neutral -> Neutral\n",
    "            return -neutral_penalty # Cost of just staying neutral all the time\n",
    "        else:\n",
    "            # Neutral -> Active\n",
    "            return -trading_fee\n",
    "    \n",
    "    prev_ask, prev_bid = prev_state[ask_idx], prev_state[bid_idx]\n",
    "    curr_ask, curr_bid = curr_state[ask_idx], curr_state[bid_idx]\n",
    "    prev_is_long = prev_state[prev_action_idx] == 2\n",
    "    portfolio_is_same = prev_state[prev_action_idx] == curr_state[prev_action_idx]\n",
    "    \n",
    "    price_change = curr_ask - prev_ask if prev_is_long else prev_bid - curr_bid\n",
    "    price_change = price_change.item()\n",
    "    spread = (curr_ask - curr_bid).abs().item()\n",
    "    \n",
    "    if curr_is_neutral:\n",
    "        # Active -> Neutral\n",
    "        return price_change - spread - trading_fee\n",
    "    \n",
    "    else:\n",
    "        if portfolio_is_same:\n",
    "            # Active -> Active\n",
    "            return price_change # Active -> Active\n",
    "        else:\n",
    "            # Active -> -Active\n",
    "            return price_change - spread - trading_fee * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d292785a-999c-4235-ad36-b3afd7759650",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple(\"Experience\", ['state', 'next_state', 'reward'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca477d4a-c1b8-4e5d-b9f1-ac2e980f6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.count = 0\n",
    "    \n",
    "    def push(self, experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.count % self.capacity] = experience\n",
    "        self.count += 1\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        # Its fine to sample without returning clones because these arent parameters anyway, their requires_grad is false\n",
    "        batch = Experience(*zip(*random.sample(self.memory, batch_size)))\n",
    "        t1 = torch.stack(batch.state)\n",
    "        t2 = torch.stack(batch.next_state)\n",
    "        t3 = torch.tensor(batch.reward).unsqueeze(1).to(device)\n",
    "        return Experience(state=t1, next_state=t2, reward=t3)\n",
    "    \n",
    "    def can_provide_sample(self, batch_size):\n",
    "        return len(self.memory) >= batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bb5a6a7-f3bc-4140-b53e-ae7949ce0edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience(state=1, next_state=2, reward=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experience(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69f00583-5ef9-4798-86a5-c07084a59a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X_torch, shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a4849-b9da-449f-b367-05f092378bf5",
   "metadata": {},
   "source": [
    "State representation:\n",
    "\n",
    "- At any current point we want to know our current portfolio\n",
    "- The action is how we want to the new portfolio that we want, we will limit our portfolio (and hence actions) to -1, 0, and 1 quantity of the asset  \n",
    "- We look at the next time step and get reward from the action we took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a7e78-026b-40ac-94f8-27052c64904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:    25509, Epoch:       25, Value function loss: 77108.5625, Policy function loss:     -0.00.0028515625866\r"
     ]
    }
   ],
   "source": [
    "policy = ActorNetwork().to(device)\n",
    "policy.train()\n",
    "\n",
    "critic = CriticNetwork().to(device)\n",
    "critic.train()\n",
    "\n",
    "critic_frozen = CriticNetwork().to(device)\n",
    "critic_frozen.load_state_dict(critic.state_dict())\n",
    "critic_frozen.eval();\n",
    "\n",
    "value_fn_losses = []\n",
    "policy_losses = []\n",
    "reward_history = [0]    # 0: Just so that len(reward_history) == len(portfolio_history)\n",
    "portfolio_history = [1] # 1: Starting portfolio (neutral), possble portfolios are [0, 1, 2] i.e. [short, neutral, long]\n",
    "\n",
    "memory = ExperienceReplayMemory(16384)\n",
    "\n",
    "lr = 1e-6\n",
    "gamma = 0.001     # Discounted rate of future returns\n",
    "batch_size = 1024 # Train size\n",
    "epochs = 30\n",
    "\n",
    "policy_optimizer = optim.Adam(params=policy.parameters(), lr=lr)\n",
    "critic_optimizer = optim.Adam(params=critic.parameters(), lr=lr)\n",
    "\n",
    "i = 0\n",
    "for epoch in range(epochs):\n",
    "    curr_state = X_train[0].clone() # Clone copies but maintains grad if one exists\n",
    "    for next_state in X_train[1:]:\n",
    "        # Do not modify our training data\n",
    "        next_state = next_state.clone()\n",
    "        \n",
    "        # Update the next_state with the new portfolio\n",
    "        portfolio = policy.get_next_portfolio(curr_state)\n",
    "        next_state[-1] = portfolio\n",
    "        \n",
    "        reward = get_reward(curr_state, next_state, ask_idx=curr_ask_idx, bid_idx=curr_bid_idx, trading_fee=1e-4, neutral_penalty=1e-2)\n",
    "        \n",
    "        reward_history.append(reward)\n",
    "        portfolio_history.append(portfolio.item())\n",
    "        experience = Experience(curr_state, next_state, reward)\n",
    "        memory.push(experience)\n",
    "        curr_state = next_state.clone()\n",
    "        i += 1\n",
    "        print(f\"Iteration: {i:8}, Epoch: {epoch:8}\", end=\"\\r\")\n",
    "        \n",
    "        if memory.can_provide_sample(batch_size) and (i % 10 == 0):\n",
    "            states, next_states, rewards = memory.sample(batch_size)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                target = rewards + gamma * critic_frozen.get_value(next_states)\n",
    "            advantages = target - critic.get_value(states)\n",
    "            log_probs = policy.get_log_prob(states, next_states)\n",
    "            \n",
    "            value_fn_loss = (advantages**2).mean()\n",
    "            policy_loss = (log_probs * advantages.detach()).mean() * -1 # This should always be positive, check why its sometimes negative\n",
    "            \n",
    "            policy_optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            policy_optimizer.step()\n",
    "            \n",
    "            critic_optimizer.zero_grad()\n",
    "            value_fn_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "            \n",
    "            print(f\"Iteration: {i:8}, Epoch: {epoch:8}, Value function loss: {value_fn_loss:8}, Policy function loss: {policy_loss:8}\", end=\"\\r\")\n",
    "        if i % 2000 == 0:\n",
    "            critic_frozen.load_state_dict(critic.state_dict())\n",
    "            value_fn_losses.append(value_fn_loss)\n",
    "            policy_losses.append(policy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7defd-2d5c-48bd-9fbe-0c59a693643b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa68f85-0e26-4500-9b01-6d91ad7fd0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e3353-c819-429f-a9df-c71fc4e3a12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### OLD ###\n",
    "### OLD ###\n",
    "### OLD ###\n",
    "\n",
    "policy = ActorNetwork().to(device)\n",
    "policy.train()\n",
    "\n",
    "critic = CriticNetwork().to(device)\n",
    "critic.train()\n",
    "\n",
    "critic_frozen = CriticNetwork().to(device)\n",
    "critic_frozen.load_state_dict(critic.state_dict())\n",
    "critic_frozen.eval();\n",
    "\n",
    "value_fn_losses = []\n",
    "policy_losses = []\n",
    "reward_history = []\n",
    "portfolio_history = [1] # 1 is the neutral position (Possble positions are [0, 1, 2] representing [short, neutral, long])\n",
    "\n",
    "memory = ExperienceReplayMemory(16384)\n",
    "\n",
    "lr = 1e-6\n",
    "gamma = 0.001    # Discounted future returns\n",
    "start_action = 0 # First action to take is to hold a neutral position\n",
    "batch_size = 1024 # Train size\n",
    "epochs = 30\n",
    "\n",
    "policy_optimizer = optim.Adam(params=policy.parameters(), lr=lr)\n",
    "critic_optimizer = optim.Adam(params=critic.parameters(), lr=lr)\n",
    "\n",
    "i = 0\n",
    "for epoch in range(epochs):\n",
    "    curr_state = X_train[0].clone() # Clone copies but maintains grad if one exists\n",
    "    for next_state in X_train[1:]:\n",
    "        portfolio = policy.get_next_portfolio(curr_state)\n",
    "        # After this point, we are in the next state\n",
    "        \n",
    "        # Update the default next_state with our current portfolio + action\n",
    "        next_state = next_state.clone()\n",
    "        next_state[-1] = portfolio.clone()\n",
    "        \n",
    "        portfolio_history.append(portfolio.item())\n",
    "        \n",
    "        # Might need to clone prev state here jst to make sure it doesnt break log_prob\n",
    "        # Might need to clone next_state before we call the advantage step, just to make sure its never changed\n",
    "        reward = get_reward(curr_state=curr_state, next_state=next_state, ask_idx=curr_ask_idx, bid_idx=curr_bid_idx, trading_fee=1e-4, neutral_penalty=1e-2)\n",
    "        reward_history.append(reward)\n",
    "        # Check that the type of reward is just a python float (Not a torch float)\n",
    "        \n",
    "        # EXCEPT FOR LOG_PROB WHICH MUST HAVE ITS BACKWARDS GRADIENT TRACKED\n",
    "        # If anything goes wrong, detach all 4 here, but first check that all their requires_grad are false if so, theres no point detaching\n",
    "        # Or just save the raw data .cpu().data.numpy().tolist()\n",
    "        experience = Experience(curr_state.cpu().data.numpy().tolist(), next_state.cpu().data.numpy().tolist(), reward)\n",
    "        memory.push(experience)\n",
    "        \n",
    "        curr_state = next_state #.clone()\n",
    "        i += 1\n",
    "        # print(f\"Iteration: {i}\\tEpoch: {epoch}\", end=\"\\r\")\n",
    "        \n",
    "        if memory.can_provide_sample(batch_size) and (i % 10 == 0): # Train weights every 10 steps\n",
    "            states, next_states, rewards = memory.sample(batch_size) # Check that all of them do not have gradient properties, we dont want to change them inplace cos theyll be buffered\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                target = rewards + gamma * critic_frozen.get_value(next_states)\n",
    "                # target = target.detach() # Ensure that this is not necessary, that target has no gradient properties\n",
    "            advantages = target - critic.get_value(states) # STATE_VALUE SHOULD BE RECOMPUTED FOR EACH WEIGHT UPDATE\n",
    "            \n",
    "            log_probs = policy.get_log_prob(states, next_states)\n",
    "            \n",
    "            value_fn_loss = (advantages**2).mean()\n",
    "            policy_loss = (log_probs * advantages.detach()).mean() * -1\n",
    "            \n",
    "            policy_optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            policy_optimizer.step()\n",
    "            \n",
    "            critic_optimizer.zero_grad()\n",
    "            value_fn_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "            \n",
    "            \n",
    "            print(f\"Iteration: {i}\\t\\tEpoch: {epoch:8}\\t\\tValue function loss: {value_fn_loss:8}\\t\\tPolicy function loss: {policy_loss:8}\", end=\"\\r\")\n",
    "        if i % 2000 == 0:\n",
    "            critic_frozen.load_state_dict(critic.state_dict())\n",
    "            value_fn_losses.append(value_fn_loss)\n",
    "            policy_losses.append(policy_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e8a90-77fa-462e-85d9-450b9c2e2695",
   "metadata": {},
   "source": [
    "# Instability\n",
    "# Pretraining\n",
    "# Penalising of neutral position\n",
    "# Time partitioning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7ace4-1728-4921-b422-e4ec055a45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic.get_value(curr_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e54758-6110-4da1-be5b-c9686fb47827",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rewards = []\n",
    "prev_state = X_test[0].clone()\n",
    "for state in X_test[1:]:\n",
    "    action = policy.get_action(prev_state)\n",
    "    \n",
    "    curr_state = curr_state.clone()\n",
    "    curr_state[-1] = action.clone()\n",
    "    \n",
    "    reward = get_reward(prev_state=prev_state, curr_state=curr_state, ask_idx=curr_ask_idx, bid_idx=curr_bid_idx, trading_fee=1e-4, neutral_penalty=1e-6)\n",
    "    test_rewards.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc728d-636c-4113-96c7-ca0406f9da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(test_rewards).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc88325-d98c-4984-858c-daf7c8a489ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5026c95b-0f5f-4cb0-9ddd-4bc2db891a44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcab614-96f0-4764-af67-c75a17b74067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6cfeaf5-8892-42cb-b83c-db8bdc1f339d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28ef07-8a15-47b6-8909-397513460536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee3ffce-375a-49be-8677-2479ddc6dd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2cbb7f-2b27-4e24-8cc8-b2a55dcc698e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0aa92-d24e-44ba-8cc3-3e65ed5662ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65180fd6-cf6c-4886-85fb-f27e0cc49970",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy.state_dict(), r\"../logs/policy_model_friday.pt\")\n",
    "torch.save(policy.state_dict(), r\"../logs/critic_model_5s_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a11dff-d1c6-490d-9567-8e82122781e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58510af2-b361-4538-90a7-cb40d061f6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABB40lEQVR4nO2dd5hU1fnHv2c7ywLLsrt0WHrvCwiIdKVYosZEjLHE2BKNSTQGxGiMoqhJTIwaW4waW/QXDEY6UkWKC9J7WTq7S+9bz++PuXfmzJ3by9x7Zs/neXi4c/fOzJk7d977nve87/cllFIIBAKBgF+S/B6AQCAQCJwhDLlAIBBwjjDkAoFAwDnCkAsEAgHnCEMuEAgEnJPix5vm5ubSgoICP95aIBAIuGXNmjXHKKV5yv2+GPKCggIUFRX58dYCgUDALYSQfWr7RWhFIBAIOEcYcoFAIOAcYcgFAoGAc4QhFwgEAs4RhlwgEAg4RxhygUAg4BxhyAUCgYBzhCH3iG1Hz2DNvhN+D0MgENQChCH3iLF/WYYb/74CALCj5CyE7rtAIPAKYcg9ZtnOMlz50lJ8WnTA76EIBIIERRhyDzh48kJ4e0/ZeQDApkNn/BqOQCBIcIQh94Cr//Z1eJuQ0P8UIrQiEAi8QRhyDzh1odLvIQgEglqEMOQeQySXvEY45AKBwCOEIfeYJDm0wqkhP32xEou3l/o9DIFAoIMveuS1iSTZI+fUJe/11DwAwIrJI5GSlIR6GSnISE32eVQCgYBFeOQekywZ8mpeXXKJQycvov/UBbj7fdEQRCAIGsKQe0xSkhwj58+QVzOzCDnWv2znMb+GIxAINBCG3GMqqmoA8Bkj/4wpYuLxRiQQ1BZcMeSEkLGEkO2EkF2EkEluvGai8NjnGwEAGw+d9nkk1lm7/2R4W74hCQSC4OHYkBNCkgG8CmAcgK4AJhJCujp93URjV+k5v4dgmYXbysLbwpALBMHFDY98AIBdlNI9lNIKAJ8AuM6F141h7f6T+NdK1SbSgadj4yy/h2CZLk3rhbfLq6p9HIk7LNtZFhX3FwgSBTcMeXMArCLUQWlfFISQewghRYSQorKyMuWfTXHDa9/gd//dZG+UPlOHw5S91OTI5XGpkm+P/L1vivHjf6zGvf9ag0uV1bhQUeX3kAQC13DDkBOVfTFuD6X0TUppIaW0MC8vz9Yb3dSvBZKT1N5O4AVyDjwAXKzk2yN/8ovNAIAFW0sw8Nmv0PWJuT6PSCBwDzcM+UEALZnHLQAcduF1Y8hMS0ZWOp81TOyd7ejpS5i3+ahvYzFLCnPTvFjBtyFnOX1RaOEIEgs3DPm3ADoQQtoQQtIA3AzgCxdeNwZCCLcNGs5dikzlL3vuK9zzrzWBr/ZMSY4Y8tx66T6ORCAQ6OHYvaWUVhFCHgAwF0AygHcopZsdj0zr/bx6YY/Zc+x8zL7yqhrUSQtu7Jz1yEvPXPJxJAKBQA9X4hSU0lkAZrnxWnos3VmGs5eqUFNDwxWTPHHk9EU0bVAn/Dgp4OVYycwAd5fxlz4pENQWAm5KopG77ZznNOOAXTwEgJqAJ4IwSSu4kEAxct7ZVXoWp4XmvYCBK0POO5sU1Z3ztgR7wZP1yGes82T9WmCD0X9eil5/mAdKaULk9wucIwx5HFGW6Qfdy22bW9fvIbgCrwvkRkybsw2dHp+DS5ynhgqcIwx5HPnbwl1Rj9fsO6lxZDDIzkzV/XtNDcWXGw4HPvsm4MOzBLtW8cnqUB1eIqWGCuzBpSHn9XfJ2/Ks0Xl+++s9eOCj7/DWsj1xGY9dEskjH/WnJeHtSGNvQW2HT0Ous0hYU0NRMGkmVuw+Hr8BmWTigFZRjzNSg336tQygPJWfvSkU4//P2oNxG5MdWI98dJd8/wbiMrJjkEg3KoE9gm1JFDw2vjMAfW1s2bhMfGtlXMZkBaXg18mAZx68sVTd035pwQ4AwNAOIamF8T2axm1MdqCMz9q5SX0fR+IuorG3QIYrQy73itQz5JXVAc/pY5i54YjfQ9BFTvdUsuFAaNFW9gRPnq+I25jswF4uQV9gtoKczsqrR37yfIUoNHMJrgy5GQ9EiGp5z4o9obDVXqla9b0VwZYWZu3cO8v3+jcQl5Hz/Ks4dcn7PD0fA579yu9hJARcGXLZRut5IETY8bjBy+wnUdvUyR457xrrmw+fRsGkmVi+S/SDtQtnhtzYI1+4rTROoxGs2nvC7yGYwoyZW7PvBHfVkvLvgUeP/OylyLletSd0HfGgCBpUODPkof/1PKzpaw/FaTT2KJg0M7w9pH0jH0finFOcGD6jGHJNDcWNf1+B/s8uiNOI3KFCmhFVB13rQYW73isKbyeJNErHcGXIIzHyxPjK2+Xpt3/79b/X4Y0lu+M0msRFy2GVi2vk64m3vqRlZ8sBAJXV/P0eVjOzORJetPVrNPzDlSH/amsJAGDu5hKfR6JPblaaqeOGddTvlDT9u0N4bvY2N4bkCT8Z0sbvIZhiZ8lZ1f1ycU015xZk2U57rRODgpmZtkAfrgy5XNK+WaFZEjQ65NfDgIIcv4fhOWzjiSAza6N+7JV3+9Gf82st7JH7PA67VFbX4Mjpi76OwZEhJ4TcRAjZTAipIYQUujUoLY6dC+UrT/8u2HFwmXuvaBveVmu+zLsB4SVDyGicvHuCfI+e/3z44S8uxqDnFvq6WO7UI98E4AYAS10YS8JxQ98W4W219HZesg0eubKj6v5kXiy5Abyn7/FqAGXCoRW+lijCHDoV8sb3Hj+Pgkkz8cKc+IdDHRlySulWSul2twbjNvuPX/D1/dNTIqeXqBi9d7/RLk4JkjSpPBNSsu+Ev+fXLEa3G87teNT4D526GDYsvJCUYEkMry2Of4ICVzFyqyze4W9OudywuHl2HdXp/bW9mms+99lZW70almXUus4Pe3FR4CUGzBKkm6YdWBnhIdMWYsi0hT6OxgbhxU5/h2GH+VsiiRd+zuwMDTkhZAEhZJPKv+usvBEh5B5CSBEhpKisLD6r7E/M8KwHtCmy0lOw59nx+Pq3I2LavAFAWor26f88QPnwahWc+yzMdmZvPIKHP13v5pAsYRQBktP4eOVVHzxAN3lF0ukv4VB3ha1G9bPS2dCQU0pHU0q7q/ybYeWNKKVvUkoLKaWFeXn6aXeJRFISASFENUb+yGfaxu1suf99Se8YXAAAyJNmFlr8aGAr3b/f/+HaQEvd5tQ1ly4aVJbu4Dv9cL8UovuawxJ91iMv97EOIaFDKwBQFRA9ECeStSv3+KOt3jAzZOAyVDJuWDLT9P8u49fUU219goX3xc5EoVmDDL+HYJnm2XXC236G6JymH15PCDkIYBCAmYSQue4MS52hHXItP+cSZ9V6amw4eMrX97/r8kjhz4hOsbMps2tUF3260I0WO3kR/0p08uvzZ8gz0yNOjJ+GPMXJkymlnwP43KWxGJKVbn24lVU1gH5kwFcqq2uQmqx/Pz1wwt8shJzMSOhBzbs9c8ncbMPvrIS05KSwPgmL8MiDAY/fQgoTMy2vFKEVUzw6tnN422zIRM94FEyaiQc+Wut4XE6oMqGToews5Cdqsf5Pi8zFv33LOpfeWCvCkkjNJriG+a1eqKhC8TH1xiZBgu1/4NeME+DMkNfLiHjk7afMxser9xs+x8jb+tLnFDq/vVSrqHnk3Ztrt0+7UBFZtPW74EPtTP/+i834/uvfxH0sbsN7URAQnX54zd++xvA/Lg7852INebpOFprXcGXIG2ZGZxdMnr7R8Dls9eT3Xl2OgkkzQSlVzY32A7OG/OBJf4tvtj09FjunjlP1qjs11jbk5y5FDHnxcX88rHQpdKW2KPvuN8Wm1QNPnK/ArW+vCswCOksiRIc2MhpKu6U2g35mgpiBTSuuY3LR35Nx+PbONlBr4zZj3SE89vlGzFh3CFe9FKsUIHvk5VXVWHfgFIBQqKLXU/PCx/h51zf7A/xi/WFvB2JARmoyUpOTVPPh9VILDzA3oO/2n/RkbEZc1i6k+/7s9T0cvU7fp+fj613H8JcFO90YlqtsDLiQnFlOKPq/ql1vQYKNka/c41+jFa4MuRoPfbIOH63aj4c+WYftKnKlssfL2uoFW6MrPtlcUDegBss2j42PxPrNZkzsLg1GvFC+GZqF9XZ//78tLo/GHLIxyM5MDe8zyo3XY2kAZWPX7ou+SV7kNO4fxNmOHkmMIfdz7NwbciNkj5zVn1De4z2Z8us4EmO7NQ1vLzB5EwlKQc1Ri9V3NQGd81/ZtbHt5244GDzvN1Eyb5T6PX7VUJiF9cg/W+Pfb7TWGPJ3lxeH9ykjNM/Oiq9aGTtb3HZUvekBb8zZpK75HVSFx/QU/+KZXrCr9FzU44BHJDRR9hooDbh8QpOA5L4nviGXYipsCp/fcbcWDSPVYO9+U+z49X76XhEGTPW336RWyCWonmKqg6YYakVRfnP8fLANnlneWxGdarv1yBmfRmKO5sxvWYsDcVAJTXhDrpanbbaAxSuUKXz3f7DG0est2Friu+eilX0TVI/cib5Kn1YNXRyJO+woOYdnvvRnDcJN9ipyx88HQHNID6M8idkbj2DoC4swd7N+lyqnJLwhVzMw3xa7lz1RMGkm7nm/yPhAHWZrhCW0+GprCQomzcSlyurAlJdrlScrPfJF2/2VFt7+zFisf+JK1Wpas176V9v8/Qxq7D9xAW9/HdG3NzIwj/93o+/tydSQhdpkgt5OUOs0y5lwf/0qlOH0vMe9dxPekFfVUFMypSt2H7fdqmmejayXz+4bFPV44bYSTJu9DW8t3YOX5u/Qfe5d74VuHH9ZsBMdpswO7/fTe9GOkUffaO79l7PZh1PSU5LRIDNVtUK1spqaWpxdbzFzx20GS+mUeuhlTi3dUYYPVu7HoOeCp1uuDDX6HQY1Qqvx9XvS5xgjLapf3auZp+NIeEO+cGsprnhhkeFxE99aibsdetZWUBqSn7xbhNeX7MbUWVvDd3Ejtijih/d/GF+5gbuHRsS0tHRwlB55RUAKPM5p3PQCbjcAAIUOmy3zpPv9viJmHjS0GnuvV2Q2VXtc1pzwhvyVRbtMayDEs6jCDU9DWcjkti61UT78lAldw9t7NHQxzGjJ+MEf56nPeoK6OGsVvdCKXkMTgTt8LjWIl9OeX13kbfMP8Y0yxEP0Ro7D2jXkbJpZ/YxUnSPdw8k9RxlaCTo3v7nS7yG4QmLcjviHlajwEu4MuRnx+U1PXRWHkdije/MGANTlBsww+s9Lwts8GEmzOiZASIagYNJMX2P9RfvcWwj3k5Pn1RtmA8CR0/yEVngnXrN87gz5VBN6GXZ0y+OFrJBWetb5jyloYQu1XPYVFirzXpbWBnjrAu8Hcnu9azUW0fQ07qd5nEHhlMnTN4S3B7Zxth7gN/G6aTrtEPQiIWQbIWQDIeRzQki2S+PSZJCJFfsgI3viWw47L3RwMw3u7veL0PP31hs8sQuepWfLY7I+9Ao6LlZUo2DSzHAWiBzztzlZiSv/WlHs6/s/873uWPzIcNw3rJ3q33lYtNXi49UHwtu5Bpo4X244jNV7/ROrCgpOPfL5ALpTSnsC2AFgsvMh6RP0dCQtnrq2GwCgsVTSm5xk7tSP7dYEQGiBykxq3L7j5215tPO3lOCMjXjelAldo8JEz87aitcW78Kri3bh653HsKdMW8emyxNzAADXvbocbSbPDEuXlp3VDgsEhd/N2Ozr+xNCUJBbF1qX0Xf7T8V1PF5xQ5/mun9/4KPv8IM3VsRpNNaZOKBlXN7Haau3eczDlQC+72w4xqTw4K6p0KBOaGFSzopol1fX1PPaSsdVVNXgqf8ZG49hLy4GABRPm2BjlMZ0bJyFHSXRuh5JBJCXidmiFCuwWRYT31rp2fhlmmfXSYgQDtFQZ1u0rRRjuzeJ82jMc1nbHNRQGHrTnPptYeqkxifM62aM/CcAZmv9kRByDyGkiBBSVFZmP00uycCQB0XERok8bnkhz6wIPevtKnUo/ECttJ3HWVLvltnh7c0BXhw34rDGzSgoFb9G9GrRILydkRprjgLeIMgQg3a8rmH4NoSQBYSQTSr/rmOOmQKgCsCHWq9DKX2TUlpIKS3My/NOdKgHc2FYpaeD5xr9cORYsayFLnvoRtjNbvEKtUU0O4a8vMpfvWy2HL9OKr9KiFp579OlPOag8+wNkeQFtdkFL4b80bGdVPfHy8kxNOSU0tGU0u4q/2YAACHkdgBXA/gRDUCDPSvFDl8+eHnUYydVh9e9slz373JZ9TVSlkGP5sY3jXuHtQ1cKKkP48nK2LnZjPrTEuODPIRN+DGa5Vnl2LlydJwyG2vikMro1E6U+lzlycoJq30NM3Q6YwXA3ITRSpm1s+5kB6dZK2MB/BbAtZRSf5tKSuRkmle1664wpk66qSvL5ZVc3j4Xz17fA9MkD0StibGS7/afMr0oGi8KcmNj+1rl7nocPOlvfDpNMbNonh2RIy2YNNNRT9eVe46joroG//h6j+3XMItTQ+53izi2a5Oa99q5ST3N576+xPvza5aSM7F6Tn+at91Ug3g3cGolXgFQD8B8Qsg6QsjrLozJEeN0Fnj6tsrWfa4TQ24EIQS3DGyFukyOe1sVo8hy//B2cYuxmaVRlv0WafHgyw2hoiIjqeI7hxREPf7rzb2jHlsVxrrzn6vx7vLQQq/sKJq5WTtFa7HTLLIAm1/kZqVj/q+uwPZnxqrelFro6H1PD0jXLEB9Nv+3hbvi9v6OzASltD2ltCWltLf07z63BmaFF77fM7w9uH2u5nFv3VaIFZNHav69R3PtbvBeoKVPIjOiU37gFhKv6KB9fvUY2Tnf0vEXK6qxp+yc8YEKXl8S0rQoNji3rCcIhISoWFXB295ZjRnrDuGjVfux/ehZPPCRtiDZ2v0nsWh7GX7/vy2YPH0DHvz4OwDaC5FuUi8juMVvZunQuB7SU5JVb3xv6HjdO0utXx9uc3XPUNtG5fWk5Lre3qof8n8VALipXws8+n8bDI8z8iYbBzDjJWiLnXa9TPZzmIkdT/jbMuwpO285DTFZGp9Ryj0bSlEbIxBq7G2GF+dsD2+zxSzxyOXu2SLb8WtQSuMyezBCLZxlFLKU2Xb0DDo3ia8jBgDt87NMHee1bQnYxN0eblyEjeunx32FvI9BqAfgN29eCauRc+PfvzE8Xi4ksrqgRcKGXP95ateM3evIigyB2ygvDzNaREriIRbnNWv3nfL1/W8b1Dq8PaxjbFae1wuzCWHIraJ2FyUghrKtbqOnhyHjdkaFEVqdfpxy1+VtbT3PqqysfLrMVMFqPddNvO7XyIbesjNT0aWpda/UirCZH5j5Lg+e9DfXol1exKaoXUdeO4m10pD/5/7BmPerK6L2ERL/nFUzGhHJJrzEn49Q19uwQ+ffzXHttVhaNcq09bwSi71I5fCIHVlxM+dayc6Ss7p/P2Wz65RZ2CEnE4L7hlu/FvQM5e3vrI5qXO4HlSZUPl9b7K3etxXU1rXsVjybfk9PXz1AfHDXwPB2gzqp6Ng4lNb0n/sH4aOfDgQBsLvsnGY3eDPc9LpxyMAqZmLk8meJF6/e0hezfjE0Lu9lVc9ZDo/YaRBhR4TssIG6ndezPDYclJREoq6Fvk/PR1GxsbNQrePBLNlRht/9d5OzQTqEA7XmKNRCdF6HSGuFIX/91n64XCPbol/rHAxunwtCCNbuP4Xvvapf2KOHm02d5fxZM81njeLBbjOhZ1N0bRaZwt97hX7YJN9AwU6PPIvPlb3qeBWL7Diq75FfqrRnhY6fK0ebyTMtKfulJJGwTDIAnDhfgadnbjV8HnvT+/e3+/FbE4kD8UTvRsPiVVjQLAsfHoblk0aqhlZuKvRWPKtWGHKv45QsZho96yGXjr//kwEA1KdpL0/sg8WPDA9rUfstq7HpsH5Ryeopo22/tlU/Rs5y2G0jddEO2w1CK598ux/7j1u//tbuPwVKgTeXmg8ZJBGCjNRk/HpMx/C+9QdOYcPBU/jf+sNYf+AUXl0Um9tcJRnyquoa/PY/G/HvogNYuqMMBZNmWh63F5h1VN5TNG6ON23zstA8u45qPrzXhUFcGvKfj2inKt7Ewp7MhSamzG5lX737jf1Y2B9v6hWO09eXtFjUQivX9mqGgty6YTkC5YVeYDMebZdNh5xrq2th1a+WU9jmb3VPq12LPWXn8H9r9ItSpq89hCteXKTZbV0L+Wu3EiKSc5mV18y1ryzHgx9/h+teXY4X526PeZ4cIy9nilreWhadvx0PuQEWWb4ZML92dTZO5fBG+NGBiUtD/purOmPZoyN0j2FjUmaq3FlD7mRa7qTJaucm9cKGSx6P3gKcWoZG31bZce/XeI9BaMUJdr8L9nleRVlGWtCL0dNlVyPJxqLtlV1Dxs+qUyLfLE5eiOjAK+O8OwxmHm7zyFWRWcWK3cdMPecNC7MXL9lwMP6yB1wacgBRsUA1WK/kxr4tDF+vnIllOu3baNdwNKiTGjZAcum1Xvphm9xQylMuU+hUUV0T9+wbpW6Jm9j9KEdVvCKn5exAaH0gHiSZzIdnuaFv86jnmkUOraxlCpiUl50ZLXw3SWG8r30mQ1NBT6O0KvtgBW4NeYrCeOTUTYsqk2UvBDWhJyWlTGzbTsaDEjsmIzszNcYj11vtvueKtnj3zv4Y1SU/fHzjehmOMyWs5mCnmliQtYvVm5IsSetV+faff9DL1vOUoQojkm0Yctm5sZpGKb/HLyRpASD2+rW7aGuXJkxh03Mu9Bh9f0Uxps7c4vh1nDBn81HPXptbQw6E4mjyD+vbKaOx5vEx4b+x9s+qmfGrmrJeRuRGJI9AGe8cymTfJCcRDO+UD0IIlv5mBJ68pisa1EnF+fJqfLPL3HRUjcufX4iLFgTE1rs0lWybWzemdN7qTalZdsQAGIVlPr13EF6e2Cf8uKuJYhpWdtUKVtUe7cTI5SOtxrPV3qPcgaSzG2QoNOKd5rI/MWMz3lrmbS63EXaK1MzCtSF//cf9cIMUNklOIlFGj/XYrZZem9U3URN1ykp3V76GHct1vZuFs1mUtMzJxJ1D2gAklHZ2y9urbIs2HT59yVLWh5nFZDNUU4rG9RXphhav/d1MLNpoqj2gTU5UF/qHr+yoc7Qzbr2slaXj7cTIZYNs1fNTM+S7XJzR3P7OavxzuTMjajWX/eDJC5j45spAaZa7MdPXgmtDrseJ88zCjcXnmo0xqi12WdHmvqpb45h9SglUdpq8dEeZ4U2JjQNfqLC/iv/aYvMSnI+N7xyz78GR7QFEzyDUWPboCEz/2WAAoSn+Vd2iZYidXPpWfzhGXqhRvrweeVnWNFDk68BKHrldQ1FdQ2NkWEtV0mhPnq9AlY1c1yU7yvDU/6yHNT66e2DU4x0lZ7F4eym+2X0Mi7brOw+XP78IK/Ycxwcr96Hv0/PD+700pkbM3iRCK46wuoq/Mk4iSDf31/bS1EIrJ02Ue0dn39gdGTBro/mLbtWeWGMjL4Dqtc/7+Yh2aJmTiTxpsbamJlZ/xslnMFPazWKUNuakgtZMYRfLJQut8FpL6aZ2jdSR0xdx69urDI/r8/R8PGOiwMgtlIvoV760FHf881vc8tYq3PnPb029xvJdx6Ocummz4zd+AGiVE0kFtlrcZgWnHYKeJoRskJpKzCOEeCu6axMrRgkATjBpWF4yonO+pkxrOP3QYryePdqM4XcDvam8XqaIHG+WP2N1DY2J7zpZuK2ymMXQW6WNHcsYlRmUWdjYvRmsfOvyza7KpiG/74O1WG2ilB8A3ltRbOs97OCGqulJxW/Z7Ti5kaOxlEmTdiL/YYRTj/xFSmlPSmlvAF8CeML5kNxn3QFriz96YvbxhjXkTUxoGrPX/uTpzkqtzXrDytLoJGIuJCLLJsiZJgW5mTGxeUceucUwgFH2Tf0Mcw2z1V/b2k9NL7yn/Mt+qXK5JA79N43Sft3ErhY/G97M9dALZvFbz91phyC2pK8unIU0PaN1jnH6YVD4fr/Q4m04Rs5czLcNbq36HBbWA1aLc2qh11LL6CJVOoIPjOzAPFf7efLUuWHdNLx7Z3+8cWthjCaFkwvqbYspf1aNrR4TB0SHzazekNjKZSNPrr7UJUhOv9Xrcymz9Df6BXVaxCMNUW5Mbjd5rPuTc8PbXmaKBAnHVy4hZCoh5ACAH0HHIyeE3EMIKSKEFJWVWStXdsq4Htp9PIPAvVe0xTVS9sTzN/bEpqeuCv+NNeRmClqiZE19SqO8sW9zU4arGyO8NbxTPhpkpuLWy1rh7qFt8MTVXQEA3+49YTv2+9ayvZYqEt1cCHt8Qpeox1Zfmb2psPndasx6aCjuG9YunD755DXdDF/frqxwPJBvSG6kQPq5uKnGcx7F6A0NOSFkASFkk8q/6wCAUjqFUtoSwIcAHtB6HUrpm5TSQkppYV5ebAcNL3E7JdBtJo/vgr9J+czJSSRqvGxhk5nZ216mV+WFcnMLZufLqxx1tb+5f7QXHX3zUWfn1HGqnn56SjKmTOiKLMnL/OW/16kKPWmhzENX0xbR4pCDHpvKno3KxU3rnY4i2yfP66/ZtGiYiUnjOofPZ6+W2gvMPCAb8FUuJB24GZf+14piPDnDuqQvu+DpVdjW0JBTSkdTSrur/JuhOPQjADd6MkqH1PXYkLOepduws30z/jUbH6wwGSM225tSi9sHF0Q9Tk4y7rZkFMZgP6uRwiBL3fToQpL5W0pMP7d781gD+OWDl5t67oJfD8PshyIa7XaaVLCwzz5rIaUVsF6iHxRk1UY5zGc2jCOLxKlJRaiFF8urqi2vnwDA72ZsxnsrrBcmLXx4mOXnWMVp1koH5uG1AJzX0rrE5e0j+csNM/WVEp3SuUl93HV5m/BjswbUDOyP0kzF3ubD1pUIF2w1b+zUaKroE5lESCS0YtOoRHnrFpzZHw00XkfQQs34mm2dlpuVHnWsMqxlNUbuxBa7GeuPJy1zQgZcjmt3NBHrB4CruodCpxXVNfi06IDB0UCnx+dgzJ/NC55ZRRkBSElOiqoWn+tBqb7Tb3yaFGbZAOBKAA+5MCZXYH8IymmvGaxMhS9VVqN788iP2GpXGz1YgzDPgncZT7Iz01A8bUL4YmX1QezaI/Z5q/aan2JbzddmMaOSaRZl2Cie/WD9WhuxgtrPK1n6AiolQ14vw9xMmr0BP2qyKUaxDY14s6gtNrMOmRda+U6zVm6Uwiw9KaXXUEoPuTUwp7DFNkrdBjNYWSQ5cPJC1EKkmz8kP3+UVjuuNMqKzHzcNFvHzsUnr18Nt86+9TRK7773K7vaz4c3kxFjFuUnlGUBZm44AgDIMKlrE7QbV5pKiibrJBw4YX8tRgs+52Am0KsoNINRcQVbOr3h4OmoGYDdwgw1nF6knzjoTDL9O2v35Yj0KtBLOv9q34NR2T7gXqMPS9j82i5rmxPe/s/9gzDzF7Fx9QBJfqgaGi2evb5H1GMnM57n5+hHXtvlhdKE5dltYUFDw9ec0KNp4Ax527zYdGfWI/dCLTRhDXmLhnUwoCAHr9/az9bzjX54P3hjRdRjdirtpuCQ04t0lgN9h/MWF9kmj++C1GSCRnXTMKpLY6yYPBKjusR6f2YW4/ww5MqvfECbHNXjlLx8c0RBsV/rHHRrFrp5PTymI/56c28AwL4TF3Dmkv1KWzfjqlYM+S0Do/PhL1hQxVTyd4NO9+O6N8UPC1vi7dv6AzAX6yfE+cKy2/RqkR2zjz1vbjp6MglryAkh+PS+QRjb3V4OudWGxl5dSk4v0jqp9r9iqz/aa3s1w86p48OhrKYN1IuMzHwku00g1jHNEayizG5ql5dl+JzVj41CvkbF7YOjOqBvq5BX+fJXOx019r73X2tsP1eJXmglM00/nGFF3tgqaSlJeP77PaO0yOsZZJz1apGNZA/18O2QbhDKrfagAUbCGnKnWDXkXqV8OfXIzZT1xxszGih2Tuc3u47hM4Memnqo1RsYjSPbQkaU1XZvbjK8U6R2Y0xXbefmiweG4O3bCjX/rszT9xqj1Mu7r2gbOI98nIHzeN/wdq6/pzDkGizabq361KtrSa/VmxpjFN5WpcVp3LxfXWHpeDt8baLphZ2+h/tOeJeJoEXAwrOavHtnRMdezzlon18Po3U89vb5xrOUeBO0GLlRSKi+yWwcKwhDroFRWbQSry4l1tNXLjyZGYdV/WgnUq1usna/9b6pS3eo33ytpJLumjoOT14Tkgcwo9NhZETcvMEfPBn/GxVL4/rpcV+0NZPH71dHL7so21S6gTDkLtEyJ1q7wq1c0QxmYeqHilJ4NZRxbatSrixtTfQ69QrlT7PUgbKflf6dKclJYXndcyYacxg2+nDRkjv5Lq2iNmwC44pdt6lrELMHgueRG+HFjUcYcpdQlne7lfvM3r3NfP/KsIVRaEUvk6Lax5w5pQEc8OxXhs/R8nSe/MJaB3j5PGelRabAIzvnxxxnJvvDzZ9sPL+PhQ8Pxyu39InaR0j80ygPmJiFmAk/jujknr5TwaSZjp7vxY0n2GpSAgDAHYMLcPDkBVPe3dAOuVi2M2LMjRZte/5+nubf9nlY/WaEnUvdrfzcwe1Cee439G0OQgiWPTpCtbuLmXdzM7TitSQr27KvTW5dtJFmZC/c2BNny6vwj2V7cOZSJY6fK0ejLHs63++vKMZtgwpMH19yxliK2YyHe33fFpbXvZxw55AC9C9QT1/1wpALj1yiX2vj4gO/+P213fD27f1NHassa/Yi1Ske2DGAbjU9aNUoE8XTJmBg20YAQmEztepgL9Mo1eLhXnrkvxjVAfdcoZ5N8YP+LXHX5W1ACMHczSXo98wC2+/zxAxrsyM9ZHuYbEJbId665E9e0w3jezQNP75J6jMAeJP3Lgy5xMd3XxalA24Hq53SvUDZpvK8gwbMfjKonXH1p5J4i0WZUeez63zdodKT8sxF777LdirViF5hVfpBiWwH5/wylGGl9rX/fEQ7/P1HfTG6Sygk5rcuuSzNO6ZrY8uZaGYQhlwiLSXJtm55RqrcaDjbxRHZQ7kYxYZZeOIqG/0xWRnT6T8b7OZwbOPmYuccC1W6A01Wpcp8VmQ//94qZhQKtZg8rnM4k0tuOq1Ww/HwmE4Y16MpGtQJ5fkrZzOy0mK8+GL9YQDerTEIQ67ghr7NLT9n+W9HAgBaM5krXugpmCFgDVHiClvh1yLOhStaxMrZ2v+C1lhIyfzgpwOx5Q/6M0zW/pkKE7l0STsJr4xQWXROUQmtyF6vfG9nQyvdm9ePexHRL0eHFL+rlFNmlxCGXMHU7xnnarOM6do4vPDTi+nCXulTbDpI4kxaPDSqg/FBElZStezGo71EOfyXFuy0/VrrLXS7SU1OQmaa/gyTPbdD2lsTMtt21LruvRukJSeFb4by960XUctKD0lYsxlNoTTK+CI3GLfT0MIMwpArqGMib5WF7Q4UjHzW0CWqpsBmlvkeV3eaEePaWRLK/bYiMPT6En1RJj9Q3lxe/sq+IXcb9no1IxDGyq+eumBfAMwJDeqkho2wfGPRk8d45KqO+PWYjvhe72bhfTl10xw7PFZnVvL6zfJdztvXqeGKISeEPEIIoYQQ6ytUAUSeBr21VLu/Xq7khbMl8UGoMJPt3rCO9vNm25oQi7LDy1Jf0imKxsRqWG2fp1XVKQB+JCkYrpw8CisnjwrvZ8MLVq9cv0KHDetGtG3kEeg5UJlpKfjFqA5ISU7CRz8diOGd8pCdmYrqGopj54xTG7V4ce52S8b8hEHfVac4NuSEkJYAxgCwL3wdMOS759RZ2h2vuzWrj14tGoQlSwF3F7bsMkhKmWvjoCrTq/vRtb2aoXjaBFPnSf6JGKnxyRx1UPmZyBRPm4CpkrRDkwYZUcqCUU2yLV67ZlL+gOgesjIZDhQ5gdjwIfs56mekYNfUcarPG9w+F+/eOQDJhODQqYsofGaBYWNrLV5bvBtbj5jvJfuKhQbidnDDI38JwKNwtymMr5jxrCmguvqz7emx7g/IAj8d2gbLJ41Eh3z7milBuCHJhUxmF6WU35nVhsVeke7QaHnJGaYlodVv3OzNvr9KzrnZpspAdNMOJfJ1yi529m7V0FjLhBn7yQv2PeUtR8yvE8j6PV7htPnytQAOUUrXmzj2HkJIESGkqKws2NPg0xcj8b8DJy7gyOnY1kyUUtWL328bSAiJkRr1O4fWDrLXZTbnVjm99mpRySp22gyyU/bnbrC2+G4Xq9etWUneiw5zxq/UkdyVh8xODsyE2Nh1Cye/jEc+MzR7YcxUqDrB0JATQhZIDZaV/64DMAXAE2beiFL6JqW0kFJamJfnnu6BF7zGdDIZ+sIiDHpuIQCgoqomSk3Qb6OtB9sMWq+7TH+mnZZaizK/CHvkjIGuqNI2zsoFr3gKTLkNGzpQNrvwCquywZsOWZcZtsOdQwqwYvJI1b/JX7nVVEL28Hjd8D9Yuc/T1zc05JTS0VKD5ah/APYAaANgPSGkGEALAGsJIfZa8nBAx8dno/2U2QBCPza1yyctztWFWtTLSA1vf7HusOZxrGojG+/3m7BHzvzqrLSeqwiIR24Hq01N3EBueGyWt7/e69FIoiGEaHaakrHaR5Q9etps/T6iRpj9ptTWCtzEttWhlG6klOZTSgsopQUADgLoSyl1r7lggKGgqmlPQYgvKxmi0+w4KPrjWjSoE/FIF2wt0TxO+YOqqKrR9OScws52vID9nNUeFZAoyc5MNT4oIMj1GvJvjf0dPnJlR0uvtc5Cbn6zBsHrtiUTDPeRQ2pq9EMrdwwuiNtYtPjknssAAJ9+e0BTNEh2/oIwXhbZK2Xz+g+ejF2rkFGmglVU1Rh6cnaRmy3/9+dDPHn9+z5YG97+cr01T9kuNxW2MD7IRzo2zgovaL//kwGYwZx7NvxmJpsmqqLVwhiC6KTJuBaAk7zyWsFzs7eCgmpWEhZPmxDnEakj5/puPHQamw+fQY8W2qGT347tHPW4Z4sGttqtuUWOlC88sE0jbDoUyg4o14mRK9GLpzulbV5W3L7jqhqKtrl1seeYt/0+62cE2yOf81CkSK1BndSoKmrWkJtZGy89G1l4NJsHUF1Dceai/SIor39PwiO3wRtL9oQ82eDeoAFEp2VpdSySRbaUzsYXD/i78NmiYSa+engYJo+L3GDOlZv/ITUJ8DTYCkt2lMVlUT3Lgz6SLA0dhm6SkohmBhN7nZs5V2wGyWmTxnna7K2OUlqfv7EnAGf1HXoIQ67CvcPaGh6zau8JrN57Ig6jsQ/rqczaeAT7jsd6dUHWZmmXlxWVE6yXwqX8geTUNd/dPuh4NaVny/LreeyRX9m1CQoZzX83rzv2OjfTDGUrk//dyOR18tEqZ/WODTND7+Ok4loPYchVeHBkrKjTwm3aC21BZc2+iFrevC0lGPbiYs2y4gCH/8LM36L9HbBhrtdv7YdmAVE/VOPbYmsOgFdfDevg5mR6e+OrphQTB0T0+k84KMRRwhryDy0a3OMmKzvPVzjLh2/SIAOLHhmOx03IU9hBGHIV1FIIf/JukQ8jccbgdo1i9q3YcxxXvbQ03HdQqSTHK6wO+9ju6hmwXqeAmeXBj76zdHz7fG+0b4Z1jEjCWhWLA6x13dlVei7KWXBTlyjekrQsVvRW2uTWNa46tYkw5CqkpSThiaujS2qv72Ndp9xv1GKK1TUU20siGhHydRhkj/yfdxi3udP6PbHeWlBmVVZ1Yf54Uy9PxjGBaUVmByNlyjJmUXHb0TNRaYJuVhsnOxTwKrI4Q2L50mL+vVcIQ66BUqzp8+8O+TQS+6itsrMr5zU1ET9WLSe+bV5d1/pgOmE40wFdS+RIyyywnyrI6WN6eFXdKS8Ij+5ivRsTYFy41H9qRGflUmVNlLOws1R98d0OTj3yVx0IWjnJZHET/3+lAYXT33wUrCiSzItzt4e32z42K/xjVPu4C341DFv/4K8IGBBtgCdN36B6jDzFffu2wqj9dw1tE972MiXRiCBIHCtJS0lC8bQJePv2QuODVQjKQrlJIUZN7OjhyJiNsXuNMOQa8B4zBtRTvnoqcsn1Qit6KV9+MXezenhEtinKafYkJj++u0WNc7dY8pvhWPnYKOMDOUPZB9MIvQYQTlBr9WaF/HrpDt47GL8PYcg1+O6A+f6IQUVuQcfSuH50fvVfpY41PIUd9qukmIVvSIr97Oca080fGaDWjeqGG5FY5fZBrV0ejXtstiic5dUlZjW0opTGtTqx+PuP+oa3rXSw8hJhyDX4eLX9Tt9BQSlnC+in8PHCFS8uwuyNykUmubBJ+0d9ysWUt3gwZXwXTBrnTbqaG/zsw7XGBzF4NcsljBW7f3g7w+PlPp4yVvvrjnO4SOwFwpALuOT+D9di1sYjKJg0EwdOXND0yFmaeaS9Yhar2Se3Dy4IpwWOY1Iq52wKhi6d1fhwgzrRBvTIaXe6OrEL8mYaeysXaascKGWqOUt+IAy5BhxFGnT58sHgaIy7jewRPvW/zTENeVnktQI/5GFZvt/PmjAV2xeza9NIfJ9NH+WJIe2j6xr2nzCuwjRDekpksdKMjPTCbaVRj400yfX+7rRtnVsEYxQBJEHseNwaE/jJ/iiPPPabkw2onaIXt2kl6b9vOWzcJoyndQszxOPzmFmcV8oQG0VWxv11mebfdpvslOQ1wpBr4NUKe7wJyKK6p+woORdOP1T7vJPHdcGmp65CZpr/NzXZkI9/Wds4pCaTcOd7mf5tcjSOjh9B8T7VKJ42wbQiZYvszKjHRprvu1zMefeK4H4zPsPKZPJMIqRRmiGcPKCRRpkVkJmJmW42hJAYNcLL2jbCr0Zba5rgNkt/MwKzfjHU0WuM7pJvfJDHUChj5MHIPHGCMOQatM9T17cY61MKm10qqqPFfup7LFfqF3IPSbYsPIgcPhVpjnHqQoX6QhtVvwHLxn1EJ3963ubXz0BXh7n4Izr7b8iVGYPzEiCTy5EhJ4T8nhByiBCyTvo33q2B+c3h0+rdaIKsqqeGUvpVrdozEXhvRTGAkH53kNlREpmm9/7DfNz+z9Uxx1BQ1UXb/60P9V5dtN3fz9jWhqb23F+GGkOwsrFKGYx4EZSKVDdxwyN/iVLaW/o3y4XXCwTllepxs1SHAj3xJkFC/Riq03cUiHS4CXqnGyXLdx3H2UuVKJg0E+99UwxAu7F360ah2G7/goYqf40fcgtBs/RplY1OTUK9YYd2iMwmLjiUhrWLFcVCXhChFQ1uUSw2yXjV4cMr/JT4dJO3btPXA9kiNQv4Yf+W8RiOq2yWMlie/GIzgFBpk9rX1rdVyIB3buKP1IBMfn1r3ZfYZgpWO957gWzGnZTXs9WdQcANQ/4AIWQDIeQdQoimq0AIuYcQUkQIKSorC/b0F9D2ZDsz+bwTBwTfaCRKCltGajIa1zcuc9dSRwwylyqjPVNK1fvBdpPi04U+e+QAwk0ilpoIZbGJA051UdxA9shvvcy+/MGYrvYUI73C8KwSQhYQQjap/LsOwN8BtAPQG8ARAH/Seh1K6ZuU0kJKaWFenj+LNVbQUsrr1LheeNuJalq8SBA7DsBcBk4yh/mWJYw++bnyKk2PvLAgB6seG4Xrevuvjd88O+SV3/ZObIxfZljHPOTXS8eITpEFziB8Py2lFNDcLPtdkYLwOVgMUxgopaPNvBAh5C0AXzoeUUBQlhPLsEUldTgw5E6b3gYJM78drUXqIMMWlSzZXhaKkWvcgZWiZ36RbMKzpgCaqiQHrJg8EoOeW+jBqMzx2PguGNohD3UdLLYGbabrNGuFVY+5HsAmZ8MJDkM75KFXiwa6Je48dGqXvQ8lL/3Qm64zXnLYhDZHp8b+xo/twMqofrhqHwDg653BDj+yRTTlVdWqZeyhEFEsDT3uD2pERmoyxnRtHDhj7ASnAasXCCEbCSEbAIwA8CsXxhQI6qQlY8YDl6N784h+t9KoX9OzWbyHZRmtClU2eyCRCEAIVpdRKnnU5UwYT56yr91/Kl5DssUf5+0Ib3d6fA46TJmtepza5RcU+8kmLqzac1zzOLak/9VbgrXIKeOoOoRS+mO3BhJk1j0xBhcrq9FUoZ6XHuCSZRmt34yRUBCvBL2S9aruTfCVQrSplImR19cI6fFC36fno0/LbPzjjv6aaZRByaRiZ9T/XXcYA9vGNisHgMb1MrAJocyiCT2DJ2ELiPRDU2RnpsUYcV7QWpRJ9aibt98EWQ8EAG7q1wId8qOrhvu0imShzJSa+Ra29j8zxQ4nzleEb1QUVHVG6FUneSc00wmTFhb4r3NjRPDOqMBVtOKAQdEecZvWjYKd508IiSlzz1dJqyzax3+Hqpoa/TDKgAAYyH9I/UrLzmlLO8jyx0oZ3iCRmL/mOMHqIPNGoqg78khMO7qAh4PssGh7aUhqQOOzfTNppO+LnkAklPX+in24fXAB2qloLMm/laDGxwHhkTsiaLmkVuB57LyjvIl+sf6QTyPxjjv/+W1I00TjMmuWXScQ+vBsdWfxMXVtcVktUVk3sv6JK70bmEWEIa8FDGnfCL8eEy2BmiiG3EkHdL+YrWjVptYfNug1CkbaNwCwau8JrN57Ig6jsQ9babps5zHVY7SkWRoEqEZDGPJawIc/vQy/YHoZ/thBaXLQeHRsZ7+HYJmLlcZiUUHv7PTXm/vE7Nur4dEGma1HIp2a3v2mGAWTZmoeG+RoZLCvFoGr7HhmHDYfPh2VJcE76w+c8nsInhDAxI4o1GYMY/68xIeROKN949iY+KZDp7Fgawk+XLUf304ZHdZmCfJaRsAvF4GbpKUkJZQRB4BTFyv9HoInBGEhUI86ackxCqGsyiEvqMken75Yib8s2BluUhLuBxtcOy4MuYBv+iRISz4lN/T1XxjLiB5M1TMAbDt61qeR2EepPAlEi5gBEdnbANtxEVoRAF2a8qdPIrPZRDd6Hjl2LvhyvErDdugUf4JlR1T0ex7/b0Qy6uFP14cbZqvVZKyeMgrVyt5xPiA8cgH6tc72ewi2SSLAk9d09XsYrsNDF5tEqEVQk7LNYzKh/rP2YLggSC3RK79eRiCqvoUhF3BTrn/nkAK0ysnEtb0iYmXjezRFWgof47dCAQedqA6evOD3EByjVuHcRdGB6etdobTEIKslJt4vQGAZXgz5k9d0w9JHR0Qtql3RMU+zCQjPzN0c/M7ury3e7fcQHNOBaRQjM2dzdJ7/Gg7kEkSMXMBdQ+kb+7VA3fQUjOycj+QkEogYpds8NKq930MwpCoBzzuv8OGKCTwlCH0UrTK2e5NwSCURDUqflomVJhpk3vxxP7+H4BjHv2BCyIOEkO2EkM2EkBfcGJQgvvCwsKZHVQJqqydxIKEQ4JCxJdrnxxYF8Yaj0AohZASA6wD0pJSWE0Ji258IAg8PRkOPymq+b0QybfPqYk8ZP2XuBJEca55JhOwbpx75/QCmUUrLAYBSWmpwvCCABKVji12qahLDI3/vzgF+D8ESQWkE7RTOL38Azg15RwBDCSGrCCFLCCH9tQ4khNxDCCkihBSVlQW7sWxtg/cLmbcY+eu3hmKyq6eMCu/rpJI9EXSu6tZEdX+7vOCnTrJwHlkEYCK0QghZAEDtG5siPb8hgMsA9AfwKSGkLVUJulJK3wTwJgAUFhYmwKlLHIKcH2uGKs5CK2O7N0HxtAlR+966rZC7G+qu0nOq+4d2yMNujkJEBxIgH97QkFNKR2v9jRByP4DpkuFeTQipAZALQLjcHNGnVbbfQ3AEz4ud79xRiNaN6qJVo0zuStzPlVep7uct5hxkVUOzOM0j/y+AkQAWE0I6AkgDoK7OnkCsmDwSpxNIdS+7TrCV9oyo4NiQj+zc2O8h2GZc9yZYpyIj3Cybr9g552v9AJwb8ncAvEMI2QSgAsDtamGVRKNpgzqB0FdwC8p57sGsjUeND+IA3uyJWtNoAOjUJBLvv7Fvi3gNxza8hxYBh4acUloB4FaXxiLwCd5vvYkyO+LNnpRXqs+EejHSwtkBaoemBW/nXQ3+SvoErtG6UUiek3dDnijwFqtVNiOWYZs1BL33KACkJ4DoGv+fQGAb+QfHe2hF4A+D2zcCAPzxpl6axzSoE3yPXEuPf6xGemUQEYa8FiNPKYVHHgx4m+Ln18tA8bQJ+H6/SBz8lVuimzKP79k03sOyjNZ5f+b67vEdiAOE+mEtpqBRXWw4eBqZacGf/uqRRADOaoJU4cyORzH9Z4Nx+NRFXN2zWdT+hjzEyLk+8yGEIa/FPHdDD1zbq5mqJjNPZKWn4Mwl9ZxmruDYnvRt1RB9OW3snaKRf1jOkc69CK3UYuqmp2B0V37zmGUSwBkHkBieIY9oicblZPJTXyEMuYB7OkgypDxkSNQ2eOk+pQZPMv0cDVUgUOfeYe0AAIPbNfJ5JAIlPBtynlRB+T3LAoGE/IPjPcQi0kD9pWPj6AYTKRzdhMRip4B75Ckw7+oQnA+fa/Y8Ox6EAG0mzwIA5GbxEx8HhEcuSADqSYVNefXUtT94oUZYct9ISiIghGD1lFH48WWtUfT4GL+HZAnhkQu4p7B1Q/z5B70wtjs/lXhqJEIuPO/k18vA09/jpxBIRhhyAfcQQnADByp7RvAeGhL4hwitCAQBIT1FpE8GlZy6wY6ZC0MuEAQE3mP8icyEHsHWjHEUWiGE/BtAJ+lhNoBTlNLeDsckEAgEgSLo+fBOG0v8UN4mhPwJwGnHIxIIBIKAkZoc7OIgVxY7SahX0g8Q6t8pEAgECUVCe+QMQwGUUEp3ah1ACLkHwD0A0KpVK5feViBILN6+rRAtczL9HoZAAfeGnBCyAIBagu4USukMaXsigI/1XodS+iaANwGgsLBQ5FkJBCokghplIhJ02RVDQ04pHa33d0JICoAbAPRza1ACgUAQJAJux11JPxwNYBul9KALryUQCASBQ0uzPCi4YchvhkFYRSAQCHiG+9CKEZTSO1wYh0AgEASWpIBb8mAvxQoEAkEAaJ+XZXyQjwjRLIFA4DrTfzYYJacv+T0M1wh6Sqgw5AKBwHX6tmro9xBcJeha8SK0IhAIBAYIQy4QCASckpUeCloE3I4LQy4QCARatAp4bFxGGHKBQCDQINLY299xGCEMuUAgEGiQmcpHPggfoxQIBAIfeHliH3y0ej+6N6/v91B0EYZcIBAINGjSIAO/HtPR72EYIkIrAoFAwDnCkAsEAgHnCEMuEAgEnCMMuUAgEHCOMOQCgUDAOcKQCwQCAecIQy4QCAScIwy5QCAQcA6hPogIEELKAOyz+fRcAMdcHE4iIM5JNOJ8xCLOSSw8npPWlNI85U5fDLkTCCFFlNJCv8cRJMQ5iUacj1jEOYklkc6JCK0IBAIB5whDLhAIBJzDoyF/0+8BBBBxTqIR5yMWcU5iSZhzwl2MXCAQCATR8OiRCwQCgYBBGHKBQCDgHK4MOSFkLCFkOyFkFyFkkt/jcQoh5B1CSCkhZBOzL4cQMp8QslP6vyHzt8nSZ99OCLmK2d+PELJR+tvLhBAi7U8nhPxb2r+KEFLAPOd26T12EkJuj9NH1oUQ0pIQsogQspUQspkQ8pC0vzafkwxCyGpCyHrpnDwl7a+15wQACCHJhJDvCCFfSo9r9fkApZSLfwCSAewG0BZAGoD1ALr6PS6Hn+kKAH0BbGL2vQBgkrQ9CcDz0nZX6TOnA2gjnYtk6W+rAQwCQADMBjBO2v8zAK9L2zcD+Le0nQNgj/R/Q2m7YQDOR1MAfaXtegB2SJ+7Np8TAiBL2k4FsArAZbX5nEhj+zWAjwB8Wdt/N5RSrgz5IABzmceTAUz2e1wufK4CRBvy7QCaSttNAWxX+7wA5krnpCmAbcz+iQDeYI+RtlMQqmIj7DHS394AMNHvc6FybmYAGCPOSXhMmQDWAhhYm88JgBYAvgIwEhFDXmvPB6WUq9BKcwAHmMcHpX2JRmNK6REAkP7Pl/Zrff7m0rZyf9RzKKVVAE4DaKTzWoFBms72QcgDrdXnRAojrANQCmA+pbS2n5O/AHgUQA2zrzafD64MOVHZV5tyJ7U+v955sfMc3yGEZAH4D4BfUkrP6B2qsi/hzgmltJpS2hshT3QAIaS7zuEJfU4IIVcDKKWUrjH7FJV9CXM+ZHgy5AcBtGQetwBw2KexeEkJIaQpAEj/l0r7tT7/QWlbuT/qOYSQFAANAJzQeS3fIYSkImTEP6SUTpd21+pzIkMpPQVgMYCxqL3nZAiAawkhxQA+ATCSEPIBau/5COF3bMdCXCwFocWFNogsdnbze1wufK4CRMfIX0T0os0L0nY3RC/a7EFk0eZbhBbA5EWb8dL+nyN60eZTaTsHwF6EFmwaSts5ATgXBMD7AP6i2F+bz0kegGxpuw6AZQCurs3nhDk3wxGJkdfq8+H7ACx+ceMRymTYDWCK3+Nx4fN8DOAIgEqE7vZ3IRSL+wrATun/HOb4KdJn3w5phV3aXwhgk/S3VxCp2M0A8BmAXQit0LdlnvMTaf8uAHf6fS6kMV2O0FR1A4B10r/xtfyc9ATwnXRONgF4Qtpfa88JM7bhiBjyWn0+RIm+QCAQcA5PMXKBQCAQqCAMuUAgEHCOMOQCgUDAOcKQCwQCAecIQy4QCAScIwy5QCAQcI4w5AKBQMA5/w/EXU+UNkKmmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(reward_history).cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ced3d-c18e-4758-84c3-fece1d9743dc",
   "metadata": {},
   "source": [
    "Theres a noticable trend where the agent is able to make money when trading from trade 49445 to 62489 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd8f6041-6902-45a7-bc63-ab07cafe9dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62489"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(reward_history).cumsum().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d889f05c-2a70-446b-be28-bfb5bdabbf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49445"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(reward_history).cumsum()[:62489].argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fd3e726-2831-4c78-9d5a-4f4dbe5b489d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13044"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "62489 - 49445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "535cf015-f235-4871-a65a-60181c6f1be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.116666666666667"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 * 13044) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b2ed686-6ee6-468a-aa68-9f6a72869c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.67361111111111"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(49445 * 5) / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2ba17-441a-42a2-b9f8-48710f20c072",
   "metadata": {},
   "source": [
    "69 hours after 930am on Monday is about Thursday morning.  \n",
    "This profit spree lasts until about Friday evening.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c34ff124-ecee-4baf-bd34-9b2fbca0ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy.state_dict(), r\"../logs/policy_model.pt\")\n",
    "torch.save(policy.state_dict(), r\"../logs/critic_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
